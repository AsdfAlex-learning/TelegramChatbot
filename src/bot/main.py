import nonebot
import os
import threading
import telebot
import requests
import time
import random
import json
import sys
import sqlite3
import csv
import logging
from datetime import datetime, timedelta
from nonebot import on_command
from nonebot.adapters import Message
from nonebot.params import CommandArg
from nonebot import get_driver
from src.storage.memory import LongTermMemory
from src.core.api_registry import APIRegistry
from src.core.config_loader import ConfigLoader
from src.bot.proactive_messaging import ProactiveScheduler
from src.core.context import ConversationContext

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

nonebot.init(env_file=os.path.join(PROJECT_ROOT, ".env.prod"))
driver = get_driver()

config_loader = ConfigLoader()
system_config = config_loader.system_config

TELEGRAM_TOKEN = system_config.telegram.bot_token
LLM_API_KEY = system_config.llm.api_key
LLM_API_URL = system_config.llm.api_url
LLM_MODEL = system_config.llm.model
OWNER_ID = system_config.telegram.owner_id

bot_is_private = system_config.bot.private_mode_default  # é»˜è®¤å¼€å¯ç§æœ‰æ¨¡å¼ï¼Œä»…Ownerå¯ç”¨

ai_chat_active = set()  # å­˜å‚¨å·²å¼€å¯AIå¯¹è¯çš„ç”¨æˆ·ID
chat_lock = threading.Lock()  # çº¿ç¨‹é”ä¿è¯çŠ¶æ€å®‰å…¨
chat_context = {}  # æ ¼å¼ï¼š{user_id: [{"role": "...", "content": "..."}]}
context_lock = threading.Lock()  # ä¸Šä¸‹æ–‡æ“ä½œçš„çº¿ç¨‹é”
user_message_count = {}  # è®°å½•å¯¹è¯è½®æ•°ï¼š{user_id: count}
user_prompt_cache = {}  # USER_PROMPTç¼“å­˜ï¼š{user_id: (prompt, cache_time)}

# ========== æ¶ˆæ¯ç¼“å†²ç›¸å…³é…ç½® ==========
user_message_buffer = {}  # {user_id: [msg1, msg2, ...]}
user_timers = {}  # {user_id: timer_thread}
buffer_lock = threading.Lock()

# åˆå§‹åŒ–Telegramæœºå™¨äºº
tb_bot = telebot.TeleBot(TELEGRAM_TOKEN)

def safe_send_message(chat_id, text, max_attempts=3):
    backoff = 1
    for attempt in range(max_attempts):
        try:
            tb_bot.send_message(chat_id, text)
            return True
        except requests.exceptions.RequestException as e:
            if attempt == max_attempts - 1:
                print(f"[Telegram] å‘é€å¤±è´¥ï¼ˆchat_id={chat_id}ï¼‰ï¼š{e}")
                logging.error(f"[Telegram] å‘é€å¤±è´¥ï¼ˆchat_id={chat_id}ï¼‰ï¼š{e}")
                return False
            time.sleep(backoff)
            backoff = min(backoff * 2, 10)
        except Exception as e:
            print(f"[Telegram] å‘é€å¼‚å¸¸ï¼ˆchat_id={chat_id}ï¼‰ï¼š{e}")
            logging.error(f"[Telegram] å‘é€å¼‚å¸¸ï¼ˆchat_id={chat_id}ï¼‰ï¼š{e}")
            return False

# ========== é•¿æœŸè®°å¿†æ¨¡å— ==========
# LongTermMemory ç±»å·²ç§»åŠ¨è‡³ src/storage/memory.py

# å…¨å±€å­˜å‚¨ç”¨æˆ·è®°å¿†å®ä¾‹
user_memories = {}
memory_lock = threading.Lock()

def get_user_memory(user_id):
    with memory_lock:
        if user_id not in user_memories:
            user_memories[user_id] = LongTermMemory(user_id)
        return user_memories[user_id]

# åˆå§‹åŒ–ä¸»åŠ¨æ¶ˆæ¯è°ƒåº¦å™¨
proactive_scheduler = ProactiveScheduler(tb_bot, system_config, config_loader.prompt_manager, chat_context, context_lock, get_user_memory)

# ====================== LLM APIè°ƒç”¨å‡½æ•° ======================
def call_llm_api(user_id: int, prompt: str, extra_context: str = "") -> str:
    """è°ƒç”¨OpenAI Compatible APIè·å–å›å¤ï¼Œæ”¯æŒæ·»åŠ é¢å¤–è®°å¿†ä¸Šä¸‹æ–‡"""
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json"
    }
    
    with context_lock:
        if user_id not in chat_context:
            chat_context[user_id] = ConversationContext()
        
        chat_context[user_id].add_message("user", prompt)

    # Prepare Conversation String (History excluding current message)
    conversation_str = chat_context[user_id].format(exclude_last_n=1)

    # Prepare Memory String
    user_summary = "ç”¨æˆ·ä¿¡æ¯åŠ è½½ä¸­..."
    if user_id in user_prompt_cache:
        user_summary, _ = user_prompt_cache[user_id]
    else:
        user_summary = generate_user_prompt(user_id)

    memory_str = user_summary
    if extra_context:
        memory_str += f"\n\nã€ç›¸å…³è®°å¿†ç»†èŠ‚ã€‘\n{extra_context}"

    # Build Final Prompt using PromptManager
    final_prompt = config_loader.prompt_manager.build_prompt(
        user_message=prompt,
        memory=memory_str,
        conversation=conversation_str
    )

    data = {
        "model": LLM_MODEL,
        "messages": [{"role": "user", "content": final_prompt}],
        "temperature": system_config.llm.temperature,
        "max_tokens": system_config.llm.max_tokens
    }
    
    try:
        response = requests.post(LLM_API_URL, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        result = response.json()
        assistant_reply = result["choices"][0]["message"]["content"].strip()

        with context_lock:
            chat_context[user_id].add_message("assistant", assistant_reply)
        
        return assistant_reply
    
    except requests.exceptions.RequestException as e:
        return f"APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}"
    except KeyError as e:
        return f"APIè¿”å›æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘å­—æ®µ {str(e)}"

def generate_user_prompt(user_id):
    """ç”ŸæˆUSER_PROMPTï¼ˆæ ¸å¿ƒå±‚+åŠ¨æ€å±‚ï¼‰"""
    if user_id in user_prompt_cache:
        prompt, cache_time = user_prompt_cache[user_id]
        if time.time() - cache_time < 86400:
            return prompt
    
    memories = get_user_memory(user_id).load_valid_memories()
    mem_descriptions = []
    for mem in memories:
        mem_descriptions.append(f"äº‹ä»¶ï¼š{mem[1]}ï¼Œå…³é”®è¯ï¼š{mem[2]}ï¼Œé‡è¦åº¦ï¼š{mem[3]}")
    
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": LLM_MODEL,
        "messages": [
            {"role": "system", "content": "æ ¹æ®ä»¥ä¸‹ç”¨æˆ·è®°å¿†ï¼Œç”Ÿæˆâ‰¤200å­—çš„USER_PROMPTï¼Œåˆ†æ ¸å¿ƒå±‚ï¼ˆæ°¸ä¹…å±æ€§ï¼‰å’ŒåŠ¨æ€å±‚ï¼ˆä¸´æ—¶äº‹ä»¶ï¼‰ã€‚æ ¸å¿ƒå±‚å¿…åŠ ï¼ŒåŠ¨æ€å±‚ä»…åœ¨ç›¸å…³æ—¶æåŠã€‚"},
            {"role": "user", "content": "\n".join(mem_descriptions)}
        ]
    }
    
    try:
        response = requests.post(LLM_API_URL, headers=headers, json=data, timeout=30)
        user_prompt = response.json()["choices"][0]["message"]["content"].strip()
        user_prompt_cache[user_id] = (user_prompt, time.time())
        return user_prompt
    except Exception as e:
        print(f"ç”ŸæˆUSER_PROMPTå¤±è´¥ï¼š{e}")
        logging.error(f"ç”ŸæˆUSER_PROMPTå¤±è´¥ï¼š{e}")
        return "ç”¨æˆ·ä¿¡æ¯åŠ è½½ä¸­..."

def extract_keywords(text):
    """æå–æ–‡æœ¬å…³é”®è¯ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…å¯ä¼˜åŒ–ï¼‰"""
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": LLM_MODEL,
        "messages": [
            {"role": "system", "content": "æå–è¾“å…¥æ–‡æœ¬çš„æ ¸å¿ƒå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¶…è¿‡5ä¸ªè¯ã€‚"},
            {"role": "user", "content": text}
        ]
    }
    try:
        response = requests.post(LLM_API_URL, headers=headers, json=data, timeout=10)
        return response.json()["choices"][0]["message"]["content"].split(',')
    except:
        return text.split()[:5]

def extract_new_memories(user_id):
    """ä»æœ€è¿‘å¯¹è¯ä¸­æå–æ–°è®°å¿†"""
    with context_lock:
        if user_id not in chat_context:
            return []
        recent_dialogs = chat_context[user_id].get_raw_history()[-20:]
    
    dialog_text = "\n".join([f"{d['role']}: {d['content']}" for d in recent_dialogs])
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": LLM_MODEL,
        "messages": [
            {"role": "system", "content": 
                """ä»å¯¹è¯ä¸­æå–ç”¨æˆ·çš„é‡è¦ä¿¡æ¯ï¼ŒæŒ‰æ ¼å¼è¿”å›ï¼š
                äº‹ä»¶ï¼ˆYYYY-MM-DD + å…·ä½“äº‹ä»¶ï¼‰,å…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰,é‡è¦åº¦(0-100),æœ‰æ•ˆæœŸï¼ˆå¤©ï¼Œ365=æ°¸ä¹…ï¼‰
                ä»…ä¿ç•™é‡è¦ä¿¡æ¯ï¼Œæ™®é€šé—²èŠå¿½ç•¥ã€‚
                """},
            {"role": "user", "content": dialog_text}
        ]
    }
    
    try:
        response = requests.post(LLM_API_URL, headers=headers, json=data, timeout=30)
        result = response.json()["choices"][0]["message"]["content"]
        memories = []
        for line in result.split('\n'):
            if line.strip():
                parts = line.split(',')
                if len(parts) == 4:
                    memories.append((parts[0].strip(), parts[1].strip(), int(parts[2].strip()), int(parts[3].strip())))
        return memories
    except Exception as e:
        print(f"æå–æ–°è®°å¿†å¤±è´¥ï¼š{e}")
        logging.error(f"æå–æ–°è®°å¿†å¤±è´¥ï¼š{e}")
        return []

# ========== æ¶ˆæ¯æ‰“åŒ…ä¸å‘é€æ ¸å¿ƒå‡½æ•° ==========
def process_user_messages(user_id):
    """å¤„ç†ç”¨æˆ·ç¼“å†²çš„æ¶ˆæ¯ï¼šæ‰“åŒ… -> åŒ¹é…è®°å¿† -> è°ƒç”¨API -> å‘é€å›å¤"""
    with buffer_lock:
        if user_id not in user_message_buffer or not user_message_buffer[user_id]:
            if user_id in user_timers:
                del user_timers[user_id]
            return
        
        packed_message = "\n".join(user_message_buffer[user_id])
        user_message_buffer[user_id] = []
        if user_id in user_timers:
            del user_timers[user_id]
    
    try:
        with buffer_lock:
            user_message_count[user_id] = user_message_count.get(user_id, 0) + 1
            current_count = user_message_count[user_id]
        
        keywords = extract_keywords(packed_message)
        memory = get_user_memory(user_id)
        matched_memories = memory.match_keywords(keywords)
        extra_context = ""
        if matched_memories:
            extra_context = matched_memories[0][1]
        
        assistant_reply = call_llm_api(user_id, packed_message, extra_context)
        if not assistant_reply:
            print(f"[Telegram] ç”¨æˆ·{user_id}è°ƒç”¨APIå¤±è´¥ï¼š{packed_message}")
            logging.error(f"[Telegram] ç”¨æˆ·{user_id}è°ƒç”¨APIå¤±è´¥ï¼š{packed_message}")
            return
        print(f"[Telegram] ç”¨æˆ·{user_id}æ‰“åŒ…æ¶ˆæ¯ï¼š{packed_message}")
        logging.info(f"[Telegram] ç”¨æˆ·{user_id}æ‰“åŒ…æ¶ˆæ¯ï¼š{packed_message}")
        print(f"[Telegram] ç”¨æˆ·{user_id}æ‰“åŒ…æ¶ˆæ¯ï¼š{packed_message}")
        logging.info(f"[Telegram] AIåŸå§‹å›å¤ï¼š{assistant_reply}")

        update_triggered = (8 <= current_count <= 12) and (current_count % random.randint(1, 3) == 0)
        high_importance_keywords = {"ç”Ÿç—…", "ç¦»èŒ", "ç”Ÿæ—¥", "æ‹çˆ±", "è€ƒè¯•", "æ—…è¡Œ"}
        if not update_triggered and any(kw in packed_message for kw in high_importance_keywords):
            update_triggered = True
        
        if update_triggered:
            new_memories = extract_new_memories(user_id)
            if new_memories:
                memory.update_memories(new_memories)
                print(f"[Telegram] ç”¨æˆ·{user_id}æ–°å¢{len(new_memories)}æ¡è®°å¿†")
                logging.info(f"[è®°å¿†æ›´æ–°] ç”¨æˆ·{user_id}æ–°å¢{len(new_memories)}æ¡è®°å¿†")
            with buffer_lock:
                user_message_count[user_id] = 0

        # Split by $ first, then by newlines to handle cases where AI uses \n instead of $
        raw_segments = assistant_reply.split('$')
        reply_segments = []
        for seg in raw_segments:
            lines = [line.strip() for line in seg.split('\n') if line.strip()]
            reply_segments.extend(lines)
            
        if not reply_segments:
            reply_segments = [assistant_reply.strip()]

        for idx, segment in enumerate(reply_segments):
            if not segment:
                continue
            
            base_delay = 2 if idx == 0 else 0.5
            char_delay = 2 / 10
            total_delay = base_delay + len(segment) * char_delay
            total_delay = max(min(total_delay + random.uniform(-1, 1), 10), 1)
            
            time.sleep(total_delay)
            if safe_send_message(user_id, segment):
                print(f"[Telegram] å‘ç¬¬{idx+1}æ®µï¼ˆå»¶æ—¶{total_delay:.2f}ç§’ï¼‰ï¼š{segment}")
                logging.info(f"[Telegram] å‘ç¬¬{idx+1}æ®µï¼ˆå»¶æ—¶{total_delay:.2f}ç§’ï¼‰ï¼š{segment}")
            else:
                print(f"[Telegram] å‘ç¬¬{idx+1}æ®µå¤±è´¥ï¼š{segment}")
                logging.warning(f"[Telegram] å‘ç¬¬{idx+1}æ®µå¤±è´¥ï¼š{segment}")
    
    except Exception as e:
        error_msg = f"âŒ å¤„ç†å‡ºé”™ï¼š{str(e)}"
        safe_send_message(user_id, error_msg)
        print(f"[Telegram] å¤±è´¥ï¼š{error_msg}")
        logging.error(f"[Telegram] å¤±è´¥ï¼š{error_msg}")

def add_user_message(user_id, message_text):
    """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ç¼“å†²åŒºï¼Œå¹¶ç®¡ç†è®¡æ—¶å™¨"""
    with buffer_lock:
        if user_id not in user_message_buffer:
            user_message_buffer[user_id] = []
        
        user_message_buffer[user_id].append(message_text)
        print(f"[Telegram] ç”¨æˆ·{user_id}æ–°å¢æ¶ˆæ¯ï¼š{message_text} | å½“å‰ç¼“å†²æ•°ï¼š{len(user_message_buffer[user_id])}")
        logging.info(f"[Telegram] ç”¨æˆ·{user_id}æ–°å¢æ¶ˆæ¯ï¼š{message_text} | å½“å‰ç¼“å†²æ•°ï¼š{len(user_message_buffer[user_id])}")
        
        collect_time = random.uniform(
            system_config.message_buffer.collect_min_time, 
            system_config.message_buffer.collect_max_time
        )
        
        if user_id in user_timers:
            existing_timer = user_timers[user_id]
            existing_timer.cancel()
        
        timer = threading.Timer(collect_time, process_user_messages, args=[user_id])
        timer.daemon = True
        timer.start()
        
        user_timers[user_id] = timer
        print(f"[Telegram] ç”¨æˆ·{user_id}å¯åŠ¨/é‡ç½®è®¡æ—¶å™¨ï¼Œå°†åœ¨{collect_time:.1f}ç§’åå¤„ç†æ¶ˆæ¯")
        logging.info(f"[Telegram] ç”¨æˆ·{user_id}å¯åŠ¨/é‡ç½®è®¡æ—¶å™¨ï¼Œå°†åœ¨{collect_time:.1f}ç§’åå¤„ç†æ¶ˆæ¯")

# ====================== Telegramæ¶ˆæ¯å¤„ç†å™¨ ======================
@tb_bot.message_handler(func=lambda msg: msg.text.strip() == "/help")
def handle_help(message):
    help_text = (
        "ğŸ“– å¯ç”¨å‘½ä»¤ï¼š\n"
        "/start_aiGF - å¼€å¯aiå¥³å‹å¯¹è¯æ¨¡å¼\n"
        "/stop_aiGF - å…³é—­aiå¥³å‹å¯¹è¯æ¨¡å¼\n"
        "/set_private [true|false] - è®¾ç½®æœºå™¨äººæ˜¯å¦ä»…å¯¹Ownerå¯ç”¨\n"
        "/help - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯"
    )
    tb_bot.reply_to(message, help_text)
    print(f"[Telegram] ç”¨æˆ· {message.from_user.id} è¯·æ±‚å¸®åŠ©")
    logging.info(f"[Telegram] ç”¨æˆ· {message.from_user.id} è¯·æ±‚å¸®åŠ©")

@tb_bot.message_handler(func=lambda msg: msg.text.strip().startswith("/set_private"))
def handle_set_private(message):
    global bot_is_private
    user_id = message.from_user.id
    if user_id != OWNER_ID:
        # æƒé™ä¸è¶³ï¼Œç›´æ¥å¿½ç•¥æˆ–æ‹’ç»
        return 
    
    parts = message.text.strip().split()
    if len(parts) != 2:
        tb_bot.reply_to(message, "Usage: /set_private [true|false]")
        return
        
    arg = parts[1].lower()
    if arg == "true":
        bot_is_private = True
        tb_bot.reply_to(message, "ğŸ”’ Bot is now in PRIVATE mode.")
        logging.info(f"[Telegram] Owner {user_id} enabled PRIVATE mode.")
    elif arg == "false":
        bot_is_private = False
        tb_bot.reply_to(message, "ğŸ”“ Bot is now in PUBLIC mode.")
        logging.info(f"[Telegram] Owner {user_id} enabled PUBLIC mode.")
    else:
        tb_bot.reply_to(message, "Usage: /set_private [true|false]")

@tb_bot.message_handler(func=lambda msg: msg.text.strip() == "/start_aiGF")
def handle_start_ai_chat(message):
    global ai_chat_active
    user_id = message.from_user.id
    
    if bot_is_private and user_id != OWNER_ID:
        tb_bot.reply_to(message, "ğŸ”’ æœºå™¨äººå½“å‰å¤„äºç§æœ‰æ¨¡å¼ï¼Œä»…ç®¡ç†å‘˜å¯ç”¨ã€‚")
        return
        
    with chat_lock:
        ai_chat_active.add(user_id)
    
    get_user_memory(user_id)
    generate_user_prompt(user_id)
    with buffer_lock:
        user_message_count[user_id] = 0
    
    # å¯åŠ¨ä¸»åŠ¨æ¶ˆæ¯å¾ªç¯
    proactive_scheduler.start(user_id)

    tb_bot.reply_to(message, "âœ… aiå¥³å‹å¯¹è¯å·²å¼€å¯ï¼ç°åœ¨å¯ä»¥ç›´æ¥å‘é€æ¶ˆæ¯è·å–å›å¤ï¼Œè¾“å…¥/stop_aiGFå…³é—­è¯¥æ¨¡å¼ã€‚")
    print(f"[Telegram] ç”¨æˆ· {user_id} å¼€å¯äº†DeepSeekå¯¹è¯æ¨¡å¼")
    logging.info(f"[Telegram] ç”¨æˆ· {user_id} å¼€å¯äº†DeepSeekå¯¹è¯æ¨¡å¼")

@tb_bot.message_handler(func=lambda msg: msg.text.strip() == "/stop_aiGF")
def handle_stop_ai_chat(message):
    global ai_chat_active
    user_id = message.from_user.id
    
    with chat_lock:
        ai_chat_active.discard(user_id)
    
    with buffer_lock:
        if user_id in user_message_buffer:
            del user_message_buffer[user_id]
        if user_id in user_timers:
            user_timers[user_id].cancel()
            del user_timers[user_id]
        if user_id in user_message_count:
            del user_message_count[user_id]
    
    with context_lock:
        if user_id in chat_context:
            del chat_context[user_id]
    if user_id in user_prompt_cache:
        del user_prompt_cache[user_id]
    
    # åœæ­¢ä¸»åŠ¨æ¶ˆæ¯å¾ªç¯
    proactive_scheduler.stop(user_id)

    tb_bot.reply_to(message, "âŒ aiå¥³å‹å¯¹è¯æ¨¡å¼å·²å…³é—­ï¼")
    print(f"[Telegram] ç”¨æˆ· {user_id} å…³é—­äº†aiå¥³å‹å¯¹è¯æ¨¡å¼")
    logging.info(f"[Telegram] ç”¨æˆ· {user_id} å…³é—­äº†aiå¥³å‹å¯¹è¯æ¨¡å¼")

@tb_bot.message_handler(func=lambda msg: msg.text.strip().startswith("/weather"))
def handle_weather(message):
    try:
        args = message.text.strip().split()
        if len(args) < 2:
            tb_bot.reply_to(message, "âš ï¸ è¯·è¾“å…¥åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼š/weather Beijing")
            return
        
        city = args[1]
        registry = APIRegistry()
        weather_api = registry.get_api("weather")
        
        if weather_api:
            result = weather_api.get_data(city)
            tb_bot.reply_to(message, f"ğŸŒ¦ï¸ {result}")
        else:
            tb_bot.reply_to(message, "âš ï¸ å¤©æ°”æœåŠ¡æœªå¯ç”¨æˆ–ä¸å¯ç”¨ã€‚")
    except Exception as e:
        tb_bot.reply_to(message, f"âŒ è·å–å¤©æ°”å¤±è´¥ï¼š{str(e)}")

@tb_bot.message_handler(func=lambda msg: True)
def handle_ai_chat(message):
    if message.text.strip().startswith(('/start_aiGF', '/stop_aiGF', '/set_private','/help')):
        return
    
    user_id = message.from_user.id
    
    # ç§æœ‰æ¨¡å¼æ£€æŸ¥ï¼ˆé˜²æ­¢èŠå¤©ä¸­é€”åˆ‡æ¢æ¨¡å¼ï¼‰
    if bot_is_private and user_id != OWNER_ID:
        # å¦‚æœç”¨æˆ·ä¹‹å‰åœ¨æ´»è·ƒåˆ—è¡¨é‡Œï¼Œç°åœ¨è¢«è¸¢å‡ºå»äº†
        with chat_lock:
            if user_id in ai_chat_active:
                ai_chat_active.discard(user_id)
                proactive_scheduler.stop(user_id)
                tb_bot.reply_to(message, "ğŸ”’ æœºå™¨äººå·²åˆ‡æ¢è‡³ç§æœ‰æ¨¡å¼ï¼Œæ‚¨çš„ä¼šè¯å·²ç»“æŸã€‚")
        return

    with chat_lock:
        if user_id not in ai_chat_active:
            return
    
    user_input = message.text.strip()
    
    # telegramæ— æ³•å‘é€ç©ºç™½æ¶ˆæ¯ æ‰€ä»¥å¥½åƒæœ‰æ²¡æœ‰æ— æ‰€è°“
    if not user_input:
        tb_bot.reply_to(message, "âš ï¸ æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
        return
    
    # ç”¨æˆ·æ´»è·ƒï¼Œé‡ç½®ä¸»åŠ¨æ¶ˆæ¯è®¡æ—¶å™¨
    proactive_scheduler.on_user_activity(user_id)

    add_user_message(user_id, user_input)

# ====================== Telegramè½®è¯¢çº¿ç¨‹ ======================
def start_telegram_polling():
    print("[Telegram] æœºå™¨äººè½®è¯¢å·²å¯åŠ¨ï¼Œç­‰å¾…æ¶ˆæ¯")
    logging.info("[Telegram] æœºå™¨äººè½®è¯¢å·²å¯åŠ¨ï¼Œç­‰å¾…æ¶ˆæ¯")
    backoff = 1
    while True:
        try:
            tb_bot.polling(none_stop=True, timeout=90, long_polling_timeout=60)
            backoff = 1
        except requests.exceptions.ReadTimeout:
            continue
        except requests.exceptions.ConnectionError as e:
            print(f"[Telegram] è½®è¯¢è¿æ¥å¼‚å¸¸ï¼š{str(e)}")
            logging.error(f"[Telegram] è½®è¯¢è¿æ¥å¼‚å¸¸ï¼š{str(e)}")
        except Exception as e:
            print(f"[Telegram] è½®è¯¢å¼‚å¸¸ï¼š{str(e)}")
            logging.error(f"[Telegram] è½®è¯¢å¼‚å¸¸ï¼š{str(e)}")
        time.sleep(backoff)
        backoff = min(backoff * 2, 60)

# ====================== NoneBotå¯åŠ¨é…ç½® ======================
@driver.on_startup
async def startup():
    polling_thread = threading.Thread(target=start_telegram_polling, daemon=True)
    polling_thread.start()

# ====================== è¿è¡ŒNoneBot ======================
if __name__ == "__main__":
    nonebot.run()
